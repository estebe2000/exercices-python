"""
Module pour interagir avec l'API LocalAI.

Ce module fournit des fonctions pour g√©n√©rer du texte et √©valuer du code
en utilisant l'API LocalAI.
"""

import requests
import json
import time
import logging
from typing import Dict, Any, Optional

# Configuration du logging
logger = logging.getLogger(__name__)

# Configuration de l'API LocalAI
LOCALAI_URL = "http://127.0.0.1:8080/v1/chat/completions"
MODEL = "codestral-latest"

# Param√®tres par d√©faut
DEFAULT_MAX_TOKENS = 1500
DEFAULT_TEMPERATURE = 0.7
DEFAULT_RETRY_COUNT = 2
DEFAULT_RETRY_DELAY = 1

# Message syst√®me pour guider le mod√®le
SYSTEM_MESSAGE = """Tu es un expert en programmation Python et en p√©dagogie. 
Tu aides √† cr√©er des exercices de programmation pour des √©l√®ves de lyc√©e et √† √©valuer leur code.

IMPORTANT: Tu dois formater tes r√©ponses en HTML pur pour un affichage correct dans un navigateur.

Quand tu cr√©es des exercices:
1. Utilise une structure claire avec des titres et sous-titres bien format√©s (<h1>, <h2>, <h3>)
2. Fournis un squelette de code √† trous avec des commentaires "# √Ä COMPL√âTER" ou "# VOTRE CODE ICI"
3. Inclus des jeux de tests avec des messages de r√©ussite (‚úÖ) ou d'√©chec (‚ùå)
4. Adapte la difficult√© au niveau de l'√©l√®ve (Premi√®re ou Terminale)
5. Sois pr√©cis dans tes explications et tes attentes

Quand tu √©values du code:
1. V√©rifie si le code r√©pond correctement √† l'√©nonc√©
2. Identifie les erreurs potentielles (syntaxe, logique, etc.)
3. Sugg√®re des am√©liorations (optimisation, lisibilit√©, etc.)
4. Donne des conseils pour aller plus loin
5. Sois encourageant et constructif dans tes retours

Utilise uniquement des balises HTML standard pour le formatage:
- <h1>, <h2>, <h3> pour les titres
- <p> pour les paragraphes
- <ul> et <li> pour les listes
- <pre><code class="language-python">...</code></pre> pour les blocs de code
- <strong> pour le texte en gras
- <em> pour le texte en italique
- <span class="text-success">‚úÖ Texte</span> pour les messages de succ√®s
- <span class="text-danger">‚ùå Texte</span> pour les messages d'erreur
- <span class="text-info">üí° Texte</span> pour les suggestions
- <span class="text-primary">üöÄ Texte</span> pour les conseils d'am√©lioration

Ne m√©lange pas HTML et Markdown. Utilise uniquement du HTML pur.
"""


def get_evaluation_prompt(code: str, enonce: str) -> str:
    """
    G√©n√®re le prompt pour l'√©valuation de code.
    
    Args:
        code: Le code Python √† √©valuer
        enonce: L'√©nonc√© de l'exercice
        
    Returns:
        Le prompt format√© pour l'√©valuation
    """
    return f"""
    √âvalue le code Python suivant par rapport √† l'√©nonc√© donn√©:
    
    √ânonc√©:
    {enonce}
    
    Code soumis:
    ```python
    {code}
    ```
    
    IMPORTANT: Ton √©valuation doit √™tre format√©e en HTML pur pour un affichage correct dans un navigateur.
    
    Ton √©valuation doit toujours inclure:
    1. Un titre principal avec <h1>√âvaluation du code</h1>
    2. Une section sur la conformit√© √† l'√©nonc√© avec <h2>Conformit√© √† l'√©nonc√©</h2>
    3. Une section sur les erreurs potentielles avec <h2>Erreurs potentielles</h2>
    4. Une section sur les suggestions d'am√©lioration avec <h2>Suggestions d'am√©lioration</h2>
    
    IMPORTANT: La section "Pour aller plus loin" avec <h2>Pour aller plus loin</h2> ne doit √™tre incluse QUE si le code fonctionne correctement et r√©pond √† l'√©nonc√©. Si le code contient des erreurs ou ne r√©pond pas √† l'√©nonc√©, n'inclus PAS cette section.
    
    Utilise uniquement des balises HTML standard pour le formatage:
    - <h1>, <h2>, <h3> pour les titres
    - <p> pour les paragraphes
    - <ul> et <li> pour les listes
    - <pre><code class="language-python">...</code></pre> pour les blocs de code
    - <strong> pour le texte en gras
    - <em> pour le texte en italique
    
    Utilise des √©mojis et des classes pour rendre ton √©valuation plus visuelle:
    - <span class="text-success">‚úÖ Texte</span> pour les points positifs
    - <span class="text-danger">‚ùå Texte</span> pour les erreurs ou probl√®mes
    - <span class="text-info">üí° Texte</span> pour les suggestions
    - <span class="text-primary">üöÄ Texte</span> pour les conseils d'am√©lioration
    
    TR√àS IMPORTANT:
    - NE DONNE JAMAIS LA SOLUTION COMPL√àTE √† l'exercice
    - Fournis uniquement des notions de cours et des pistes de r√©flexion
    - Si tu dois donner un exemple de code, utilise un exemple diff√©rent de l'exercice ou montre seulement une petite partie de la solution
    - Guide l'√©l√®ve vers la bonne direction sans faire le travail √† sa place
    - Sois encourageant et constructif dans tes retours
    
    Ne m√©lange pas HTML et Markdown. Utilise uniquement du HTML pur.
    """


def generate_text(prompt: str, max_tokens: int = DEFAULT_MAX_TOKENS, 
                 temperature: float = DEFAULT_TEMPERATURE, 
                 retry_count: int = DEFAULT_RETRY_COUNT, 
                 retry_delay: int = DEFAULT_RETRY_DELAY) -> str:
    """
    G√©n√®re du texte en utilisant l'API LocalAI.
    
    Args:
        prompt: Le prompt √† envoyer √† l'API
        max_tokens: Nombre maximum de tokens √† g√©n√©rer
        temperature: Temp√©rature pour la g√©n√©ration
        retry_count: Nombre de tentatives en cas d'√©chec
        retry_delay: D√©lai entre les tentatives en secondes
        
    Returns:
        Le texte g√©n√©r√© par l'API
    """
    attempts = 0
    
    while attempts <= retry_count:
        try:
            # Pr√©parer les donn√©es pour l'API
            data = {
                "model": MODEL,
                "messages": [
                    {"role": "system", "content": SYSTEM_MESSAGE},
                    {"role": "user", "content": prompt}
                ],
                "max_tokens": max_tokens,
                "temperature": temperature
            }
            
            # Envoyer la requ√™te √† l'API
            response = requests.post(LOCALAI_URL, json=data, timeout=60)
            
            # V√©rifier si la requ√™te a r√©ussi
            if response.status_code == 200:
                result = response.json()
                # Extraire le texte g√©n√©r√©
                generated_text = result["choices"][0]["message"]["content"]
                return generated_text
            else:
                logger.error(f"Erreur lors de la requ√™te √† LocalAI: {response.status_code}")
                logger.error(f"D√©tails: {response.text}")
                
                # Si c'est la derni√®re tentative, retourner un message d'erreur
                if attempts == retry_count:
                    return f"<h1>Erreur</h1><p>Erreur lors de la g√©n√©ration du texte. Code: {response.status_code}. Veuillez r√©essayer plus tard.</p>"
                
                # Sinon, attendre et r√©essayer
                time.sleep(retry_delay)
                attempts += 1
                
        except requests.exceptions.Timeout:
            logger.warning("Timeout lors de la requ√™te √† LocalAI")
            if attempts == retry_count:
                return "<h1>Erreur</h1><p>Erreur: Le serveur LocalAI met trop de temps √† r√©pondre. Veuillez r√©essayer plus tard.</p>"
            time.sleep(retry_delay)
            attempts += 1
            
        except Exception as e:
            logger.error(f"Exception lors de la requ√™te √† LocalAI: {str(e)}")
            if attempts == retry_count:
                return f"<h1>Erreur</h1><p>Erreur lors de la g√©n√©ration du texte: {str(e)}</p>"
            time.sleep(retry_delay)
            attempts += 1


def evaluate_code(code: str, enonce: str, max_tokens: int = DEFAULT_MAX_TOKENS, 
                 temperature: float = DEFAULT_TEMPERATURE) -> str:
    """
    √âvalue le code Python soumis par rapport √† un √©nonc√©.
    
    Args:
        code: Le code Python √† √©valuer
        enonce: L'√©nonc√© de l'exercice
        max_tokens: Nombre maximum de tokens √† g√©n√©rer
        temperature: Temp√©rature pour la g√©n√©ration
        
    Returns:
        L'√©valuation du code
    """
    prompt = get_evaluation_prompt(code, enonce)
    return generate_text(prompt, max_tokens, temperature)
