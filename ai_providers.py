"""
Module de gestion des fournisseurs d'IA pour la g√©n√©ration de texte et l'√©valuation de code.

Ce module d√©finit les classes pour interagir avec diff√©rentes API d'IA (LocalAI, Gemini, Mistral)
et fournit une interface commune pour la g√©n√©ration de texte et l'√©valuation de code.
"""

import requests
import json
import time
import logging
import mistral
from typing import Dict, Any, Optional, Union

# Configuration du logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('logs/ai_providers.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# Configuration des fournisseurs d'IA
class Config:
    """Configuration des diff√©rents fournisseurs d'IA."""
    
    # LocalAI
    LOCALAI_URL = "http://127.0.0.1:8080/v1/chat/completions"
    LOCALAI_MODEL = "mistral-7b-instruct-v0.3"
    
    # Gemini
    GEMINI_API_KEY = "AIzaSyDFjy8wVBrd4DUM3XjfbvTO4mRBSnTGCuw"
    GEMINI_MODEL = "gemini-2.0-flash"
    
    # Mistral
    MISTRAL_API_KEY = "DcCuwA1kbtGMShFRunnTJi6OtVgjQxGG"
    MISTRAL_URL = "https://codestral.mistral.ai/v1/chat/completions"
    MISTRAL_MODEL = "codestral-latest"
    
    # Param√®tres communs
    DEFAULT_MAX_TOKENS = 1500
    DEFAULT_TEMPERATURE = 0.7
    DEFAULT_RETRY_COUNT = 2
    DEFAULT_RETRY_DELAY = 1
    
    # Message syst√®me commun pour guider les mod√®les
    SYSTEM_MESSAGE = """Tu es un expert en programmation Python et en p√©dagogie. 
Tu aides √† cr√©er des exercices de programmation pour des √©l√®ves de lyc√©e et √† √©valuer leur code.

IMPORTANT: Tu dois formater tes r√©ponses en HTML pur pour un affichage correct dans un navigateur.

Quand tu cr√©es des exercices:
1. Utilise une structure claire avec des titres et sous-titres bien format√©s (<h1>, <h2>, <h3>)
2. Fournis un squelette de code √† trous avec des commentaires "# √Ä COMPL√âTER" ou "# VOTRE CODE ICI"
3. Inclus des jeux de tests avec des messages de r√©ussite (‚úÖ) ou d'√©chec (‚ùå)
4. Adapte la difficult√© au niveau de l'√©l√®ve (Premi√®re ou Terminale)
5. Sois pr√©cis dans tes explications et tes attentes

Quand tu √©values du code:
1. V√©rifie si le code r√©pond correctement √† l'√©nonc√©
2. Identifie les erreurs potentielles (syntaxe, logique, etc.)
3. Sugg√®re des am√©liorations (optimisation, lisibilit√©, etc.)
4. Donne des conseils pour aller plus loin
5. Sois encourageant et constructif dans tes retours

Utilise uniquement des balises HTML standard pour le formatage:
- <h1>, <h2>, <h3> pour les titres
- <p> pour les paragraphes
- <ul> et <li> pour les listes
- <pre><code class="language-python">...</code></pre> pour les blocs de code
- <strong> pour le texte en gras
- <em> pour le texte en italique
- <span class="text-success">‚úÖ Texte</span> pour les messages de succ√®s
- <span class="text-danger">‚ùå Texte</span> pour les messages d'erreur
- <span class="text-info">üí° Texte</span> pour les suggestions
- <span class="text-primary">üöÄ Texte</span> pour les conseils d'am√©lioration

Ne m√©lange pas HTML et Markdown. Utilise uniquement du HTML pur.
"""

    @staticmethod
    def get_evaluation_prompt(code: str, enonce: str) -> str:
        """
        G√©n√®re le prompt pour l'√©valuation de code.
        
        Args:
            code: Le code Python √† √©valuer
            enonce: L'√©nonc√© de l'exercice
            
        Returns:
            Le prompt format√© pour l'√©valuation
        """
        return f"""
        √âvalue le code Python suivant par rapport √† l'√©nonc√© donn√©:
        
        √ânonc√©:
        {enonce}
        
        Code soumis:
        ```python
        {code}
        ```
        
        IMPORTANT: Ton √©valuation doit √™tre format√©e en HTML pur pour un affichage correct dans un navigateur.
        
        Ton √©valuation doit toujours inclure:
        1. Un titre principal avec <h1>√âvaluation du code</h1>
        2. Une section sur la conformit√© √† l'√©nonc√© avec <h2>Conformit√© √† l'√©nonc√©</h2>
        3. Une section sur les erreurs potentielles avec <h2>Erreurs potentielles</h2>
        4. Une section sur les suggestions d'am√©lioration avec <h2>Suggestions d'am√©lioration</h2>
        
        IMPORTANT: La section "Pour aller plus loin" avec <h2>Pour aller plus loin</h2> ne doit √™tre incluse QUE si le code fonctionne correctement et r√©pond √† l'√©nonc√©. Si le code contient des erreurs ou ne r√©pond pas √† l'√©nonc√©, n'inclus PAS cette section.
        
        Utilise uniquement des balises HTML standard pour le formatage:
        - <h1>, <h2>, <h3> pour les titres
        - <p> pour les paragraphes
        - <ul> et <li> pour les listes
        - <pre><code class="language-python">...</code></pre> pour les blocs de code
        - <strong> pour le texte en gras
        - <em> pour le texte en italique
        
        Utilise des √©mojis et des classes pour rendre ton √©valuation plus visuelle:
        - <span class="text-success">‚úÖ Texte</span> pour les points positifs
        - <span class="text-danger">‚ùå Texte</span> pour les erreurs ou probl√®mes
        - <span class="text-info">üí° Texte</span> pour les suggestions
        - <span class="text-primary">üöÄ Texte</span> pour les conseils d'am√©lioration
        
        TR√àS IMPORTANT:
        - NE DONNE JAMAIS LA SOLUTION COMPL√àTE √† l'exercice
        - Fournis uniquement des notions de cours et des pistes de r√©flexion
        - Si tu dois donner un exemple de code, utilise un exemple diff√©rent de l'exercice ou montre seulement une petite partie de la solution
        - Guide l'√©l√®ve vers la bonne direction sans faire le travail √† sa place
        - Sois encourageant et constructif dans tes retours
        
        Ne m√©lange pas HTML et Markdown. Utilise uniquement du HTML pur.
        """


class APIError(Exception):
    """Exception lev√©e en cas d'erreur lors de l'appel √† une API."""
    
    def __init__(self, message: str, status_code: Optional[int] = None, details: Optional[str] = None):
        self.message = message
        self.status_code = status_code
        self.details = details
        super().__init__(self.message)
    
    def __str__(self) -> str:
        result = self.message
        if self.status_code:
            result += f" (Code: {self.status_code})"
        if self.details:
            result += f" - {self.details}"
        return result
    
    def to_html(self) -> str:
        """Convertit l'erreur en HTML pour l'affichage."""
        return f"<h1>Erreur</h1><p>{self}</p>"


# Classe de base pour les fournisseurs d'IA
class AIProvider:
    """Classe de base pour tous les fournisseurs d'IA."""
    
    def generate_text(self, prompt: str, max_tokens: int = Config.DEFAULT_MAX_TOKENS, 
                     temperature: float = Config.DEFAULT_TEMPERATURE) -> str:
        """
        M√©thode √† impl√©menter par les classes enfants.
        
        Args:
            prompt: Le prompt √† envoyer √† l'API
            max_tokens: Nombre maximum de tokens √† g√©n√©rer
            temperature: Temp√©rature pour la g√©n√©ration
            
        Returns:
            Le texte g√©n√©r√© par l'API
        """
        raise NotImplementedError("Cette m√©thode doit √™tre impl√©ment√©e par les classes enfants")
    
    def evaluate_code(self, code: str, enonce: str, max_tokens: int = Config.DEFAULT_MAX_TOKENS, 
                     temperature: float = Config.DEFAULT_TEMPERATURE) -> str:
        """
        √âvalue le code Python soumis par rapport √† un √©nonc√©.
        
        Args:
            code: Le code Python √† √©valuer
            enonce: L'√©nonc√© de l'exercice
            max_tokens: Nombre maximum de tokens √† g√©n√©rer
            temperature: Temp√©rature pour la g√©n√©ration
            
        Returns:
            L'√©valuation du code
        """
        prompt = Config.get_evaluation_prompt(code, enonce)
        return self.generate_text(prompt, max_tokens, temperature)
    
    def _handle_api_error(self, e: Exception, provider_name: str, attempts: int, 
                         retry_count: int) -> Optional[str]:
        """
        G√®re les erreurs d'API de mani√®re uniforme.
        
        Args:
            e: L'exception lev√©e
            provider_name: Nom du fournisseur d'IA
            attempts: Nombre de tentatives actuelles
            retry_count: Nombre maximum de tentatives
            
        Returns:
            Message d'erreur format√© en HTML si c'est la derni√®re tentative, None sinon
        """
        if isinstance(e, requests.exceptions.Timeout):
            logger.warning(f"Timeout lors de la requ√™te √† {provider_name}")
            if attempts == retry_count:
                return f"<h1>Erreur</h1><p>Erreur: Le serveur {provider_name} met trop de temps √† r√©pondre. Veuillez r√©essayer plus tard.</p>"
        elif isinstance(e, APIError):
            logger.error(f"Erreur API {provider_name}: {e}")
            if attempts == retry_count:
                return e.to_html()
        else:
            logger.error(f"Exception lors de la requ√™te √† {provider_name}: {str(e)}")
            if attempts == retry_count:
                return f"<h1>Erreur</h1><p>Erreur lors de la g√©n√©ration du texte: {str(e)}</p>"
        
        return None


# Fournisseur LocalAI
class LocalAIProvider(AIProvider):
    """Fournisseur d'IA utilisant LocalAI."""
    
    def __init__(self, url: str = Config.LOCALAI_URL, model: str = Config.LOCALAI_MODEL):
        self.url = url
        self.model = model
    
    def generate_text(self, prompt: str, max_tokens: int = Config.DEFAULT_MAX_TOKENS, 
                     temperature: float = Config.DEFAULT_TEMPERATURE, 
                     retry_count: int = Config.DEFAULT_RETRY_COUNT, 
                     retry_delay: int = Config.DEFAULT_RETRY_DELAY) -> str:
        """
        G√©n√®re du texte en utilisant l'API LocalAI.
        
        Args:
            prompt: Le prompt √† envoyer √† l'API
            max_tokens: Nombre maximum de tokens √† g√©n√©rer
            temperature: Temp√©rature pour la g√©n√©ration
            retry_count: Nombre de tentatives en cas d'√©chec
            retry_delay: D√©lai entre les tentatives en secondes
            
        Returns:
            Le texte g√©n√©r√© par l'API
        """
        attempts = 0
        
        while attempts <= retry_count:
            try:
                # Pr√©parer les donn√©es pour l'API
                data = {
                    "model": self.model,
                    "messages": [
                        {"role": "system", "content": Config.SYSTEM_MESSAGE},
                        {"role": "user", "content": prompt}
                    ],
                    "max_tokens": max_tokens,
                    "temperature": temperature
                }
                
                # Envoyer la requ√™te √† l'API
                response = requests.post(self.url, json=data, timeout=60)
                
                # V√©rifier si la requ√™te a r√©ussi
                if response.status_code == 200:
                    result = response.json()
                    # Extraire le texte g√©n√©r√©
                    generated_text = result["choices"][0]["message"]["content"]
                    return generated_text
                else:
                    logger.error(f"Erreur lors de la requ√™te √† LocalAI: {response.status_code}")
                    logger.error(f"D√©tails: {response.text}")
                    
                    # Si c'est la derni√®re tentative, lever une exception
                    if attempts == retry_count:
                        raise APIError(
                            "Erreur lors de la g√©n√©ration du texte", 
                            response.status_code, 
                            response.text
                        )
                    
                    # Sinon, attendre et r√©essayer
                    time.sleep(retry_delay)
                    attempts += 1
                    
            except Exception as e:
                error_message = self._handle_api_error(e, "LocalAI", attempts, retry_count)
                if error_message and attempts == retry_count:
                    return error_message
                
                time.sleep(retry_delay)
                attempts += 1


# Fournisseur Gemini
class GeminiProvider(AIProvider):
    """Fournisseur d'IA utilisant l'API Gemini de Google."""
    
    def __init__(self, api_key: str = Config.GEMINI_API_KEY, model: str = Config.GEMINI_MODEL):
        self.api_key = api_key
        self.model = model
        self.base_url = "https://generativelanguage.googleapis.com/v1beta/models"
    
    def generate_text(self, prompt: str, max_tokens: int = Config.DEFAULT_MAX_TOKENS, 
                     temperature: float = Config.DEFAULT_TEMPERATURE, 
                     retry_count: int = Config.DEFAULT_RETRY_COUNT, 
                     retry_delay: int = Config.DEFAULT_RETRY_DELAY) -> str:
        """
        G√©n√®re du texte en utilisant l'API Gemini.
        
        Args:
            prompt: Le prompt √† envoyer √† l'API
            max_tokens: Nombre maximum de tokens √† g√©n√©rer
            temperature: Temp√©rature pour la g√©n√©ration
            retry_count: Nombre de tentatives en cas d'√©chec
            retry_delay: D√©lai entre les tentatives en secondes
            
        Returns:
            Le texte g√©n√©r√© par l'API
        """
        attempts = 0
        
        # Construire le prompt complet avec le message syst√®me
        full_prompt = f"{Config.SYSTEM_MESSAGE}\n\n{prompt}"
        
        while attempts <= retry_count:
            try:
                # URL de l'API Gemini
                url = f"{self.base_url}/{self.model}:generateContent?key={self.api_key}"
                
                # Corps de la requ√™te
                payload = {
                    "contents": [{
                        "parts": [{
                            "text": full_prompt
                        }]
                    }],
                    "generationConfig": {
                        "temperature": temperature,
                        "maxOutputTokens": max_tokens
                    }
                }
                
                # En-t√™tes de la requ√™te
                headers = {
                    "Content-Type": "application/json"
                }
                
                # Envoi de la requ√™te POST
                response = requests.post(url, headers=headers, data=json.dumps(payload), timeout=60)
                
                # V√©rification de la r√©ponse
                if response.status_code == 200:
                    # Extraction du texte de la r√©ponse
                    result = response.json()
                    return result['candidates'][0]['content']['parts'][0]['text']
                else:
                    logger.error(f"Erreur lors de la requ√™te √† Gemini: {response.status_code}")
                    logger.error(f"D√©tails: {response.text}")
                    
                    # Si c'est la derni√®re tentative, lever une exception
                    if attempts == retry_count:
                        raise APIError(
                            "Erreur lors de la g√©n√©ration du texte", 
                            response.status_code, 
                            response.text
                        )
                    
                    # Sinon, attendre et r√©essayer
                    time.sleep(retry_delay)
                    attempts += 1
            
            except Exception as e:
                error_message = self._handle_api_error(e, "Gemini", attempts, retry_count)
                if error_message and attempts == retry_count:
                    return error_message
                
                time.sleep(retry_delay)
                attempts += 1


# Fournisseur Mistral
class MistralProvider(AIProvider):
    """Fournisseur d'IA utilisant l'API Mistral."""
    
    def __init__(self, api_key: str = Config.MISTRAL_API_KEY, 
                url: str = Config.MISTRAL_URL, 
                model: str = Config.MISTRAL_MODEL):
        self.api_key = api_key
        self.url = url
        self.model = model
    
    def generate_text(self, prompt: str, max_tokens: int = Config.DEFAULT_MAX_TOKENS, 
                     temperature: float = Config.DEFAULT_TEMPERATURE) -> str:
        """
        G√©n√®re du texte en utilisant l'API Mistral.
        
        Args:
            prompt: Le prompt √† envoyer √† l'API
            max_tokens: Nombre maximum de tokens √† g√©n√©rer
            temperature: Temp√©rature pour la g√©n√©ration
            
        Returns:
            Le texte g√©n√©r√© par l'API
        """
        return mistral.generate_text(prompt, max_tokens, temperature)
    
    def evaluate_code(self, code: str, enonce: str, max_tokens: int = Config.DEFAULT_MAX_TOKENS, 
                     temperature: float = Config.DEFAULT_TEMPERATURE) -> str:
        """
        √âvalue le code Python soumis par rapport √† un √©nonc√©.
        
        Args:
            code: Le code Python √† √©valuer
            enonce: L'√©nonc√© de l'exercice
            max_tokens: Nombre maximum de tokens √† g√©n√©rer
            temperature: Temp√©rature pour la g√©n√©ration
            
        Returns:
            L'√©valuation du code
        """
        return mistral.evaluate_code(code, enonce, max_tokens, temperature)


# Fonction pour obtenir le fournisseur d'IA appropri√©
def get_ai_provider(provider_name: str = "localai") -> AIProvider:
    """
    Retourne l'instance du fournisseur d'IA appropri√©.
    
    Args:
        provider_name: Le nom du fournisseur d'IA ('localai', 'gemini' ou 'mistral')
        
    Returns:
        Une instance du fournisseur d'IA
    """
    if provider_name.lower() == "gemini":
        return GeminiProvider()
    elif provider_name.lower() == "mistral":
        return MistralProvider()
    else:
        return LocalAIProvider()
